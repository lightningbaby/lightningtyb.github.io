<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>SSAH_reading notes</title>
      <link href="/2018/12/16/ssah/"/>
      <url>/2018/12/16/ssah/</url>
      
        <content type="html"><![CDATA[<p>有待进一步了解：semantic network，self-supervised learning，公共语义空间,multi-label annotations,跨媒体哈希</p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>​    跨媒体检索主要有两类办法：1.同时学习common和modality-specific特征，将不同模态用一个共享层，对他们的关系进行建模。2.two-stage framework：先对各模态提取特征，然后构建低纬度的公共表示空间。（Cross-modal Retrieval with Correspondence Autoencoder）<br><a id="more"></a><br>​    高纬的modality-specific 特征有助于bridge 模态gap，因此如何encourage 更多丰富的语义关系，构建更准确的模态关系，这对于在实际的应用中，达到令人满意的性能变得十分重要。（？？？之前在上一篇论文中提到，对于使用方法1来说，有利于检索的是公共语义信息，不太有利的是modality-specific特征，因为模型会把后者也进行学习，这对于模型来说是harmful！！！哦，因为本篇论文的思想是单独提取出各模态特征，采用的是方法二）</p><p>问题：如何提升跨模态检索的准确率，以及规避/减小模态鸿沟</p><p>该论文提出：利用自监督对抗哈希SSAH解决跨模态检索问题</p><p>贡献：用双对抗网络，最大化语义关系、不同模态的表示一致性</p><p>​       用自监督语义网络，用<strong>多标签annotations</strong>的方式，挖掘高纬语义信息</p><p>问题：跨模态检索</p><p>解决方法：根据各种模态生成内容标签，然后检索共同或者相近的内容标签，从而进行匹配。通常做法是，先提取每个模态的特征，根据相似度建立索引（？？？），再检索。</p><p>问题：如何加快检索速度，节省存储空间</p><p>解决方法：特征尽量短、二进制表示，用哈希编码实现。根据多模态内容生成哈希码，希望不同模态的同个对象的哈希码尽可能相近，不同对象的哈希码尽量不同。同时，又由于跨模态的相近对象存在语义相关性，通常的做法是，将不同模态的内容映射到公共语义空间。大多数用shallow 跨模态哈希方法，包括无监督方法、有监督方法。当然有监督的方法更能提纯跨模态关系，效果会更好。但这些方法都是基于hand-crafted features，会限制<strong>instance的判别表示</strong>，从而降低学得的二进制哈希码的准确率。</p><p>缺陷：</p><ul><li><p>对于模态间的语义相关性采用单一的label进行标注，但对于一些数据集来说，一个数据对象可以是有多个类别标签的。这样有多个类别标签的数据对象能更准确的描述出语义关系。</p></li><li><p>用预先定义的loss函数，构建对应的哈希码，会narrow 模态鸿沟（？？难道不是更好吗）。而去哈希码的长度一般小于128位，就会丢失很多有用的信息，无法捕捉到模态的内在统一性（说的这么绝对的咩）</p></li></ul><h1 id="Self-Supervised-Adversarial-Hashing-Networks-for-Cross-Modal-Retrieval"><a href="#Self-Supervised-Adversarial-Hashing-Networks-for-Cross-Modal-Retrieval" class="headerlink" title="Self-Supervised Adversarial Hashing Networks for Cross-Modal Retrieval"></a>Self-Supervised Adversarial Hashing Networks for Cross-Modal Retrieval</h1><p><img src="https://ws1.sinaimg.cn/large/006tNbRwly1fy8usmfcwpj31ig0mu101.jpg" style="zoom:35%"></p><p><strong>SSAH</strong></p><ul><li><p>端到端的自监督语义网络LabNet，用<strong>多标签annotations</strong>的方式，挖掘高纬语义信息</p></li><li><p>用双对抗网络ImgNet,TxtNet，最大化语义关系、不同模态的表示一致性</p></li></ul><h2 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h2><ul><li><p>Phase1:ImgNet和TxtNet各自生成<strong>modality-specific特征</strong>（这些语义信息包含在它们各自的输出层里）到公共语义空间，用于找寻模态间的语义相关性。LabNet从multi-label notation里学习<strong>语义特征（semantic features）</strong>，可以看作是公共语义空间，用来监督模态特征学习。</p></li><li><p>Phase2:把上述得到的modality-specific特征和semantic特征不断的输入到两个判别器中，在相同的语义特征的监督下，两个模态的特征分布逐渐趋于一致。</p></li></ul><h2 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h2><h3 id="总体目标"><a href="#总体目标" class="headerlink" title="总体目标"></a><strong>总体目标</strong></h3><ul><li><p>ImgNet,TxtNet各自学习单独的哈希函数，$H^{v,t}=f^{v,t}(v,t;\theta ^{v,t})$;</p></li><li><p>针对两个模态学习到统一的哈希码，$B^{v,t}\in {-1,1}^K,K$是二进制码的长度.</p></li></ul><h3 id="符号定义"><a href="#符号定义" class="headerlink" title="符号定义"></a>符号定义</h3><ul><li><p>$O={o<em>i}^n</em>{i=1}$是数据集，包含$n$个instance</p><p>$o<em>i=(v_i,t_i,l_i),v_i \in R^{1\times d</em>{v}}$是图像特征,$t<em>i \in R^{1\times d</em>{t}}$是文本特征</p><p>$l<em>i=[l</em>{i1,…,l_{ic}}]$是multi-label annotations，c是类别数，一个instance可能会有很多个label;</p><script type="math/tex; mode=display">l_{i,j}=\begin{cases}1 & 如果 o_i 属于第j类 \\0\ & 其他 \\\end{cases}</script></li><li><p>$dis_H(b_i,b_j)=\frac {1}{2}(K-<b_i,b_j>)$用来衡量两个二进制码的相似性；</b_i,b_j></p></li><li><p>$S$是pairwise multi-label 的相似性矩阵，用来描述两个instances的语义相似性，<script type="math/tex">S_{i,j}=\begin{cases}1 & 如果o_i 和o_j 语义相似，即至少共享一个label \\0\ & 其他 \\\end{cases}</script></p></li><li><script type="math/tex; mode=display">P(S_{i,j}|B)=\begin{cases}\delta(\Psi{_{ij}}) & S_{ij}=1 \\1-\delta(\Psi{_{ij}})\ & S_{ij}=0 \\\end{cases}</script><p>$\delta(\Psi{<em>{ij}}) =\frac{1}{1+e^{-\Psi{</em>{ij}}}},\Psi{<em>{ij}}=\frac{1}{2}<b_i,b_j>$，可以看出两个instance内积越大，$P(S</b_i,b_j></em>{i,j}|B)$也越大，它们就越相似。</p></li></ul><h3 id="LabNet-自监督语义生成"><a href="#LabNet-自监督语义生成" class="headerlink" title="LabNet (自监督语义生成)"></a><strong>LabNet (自监督语义生成)</strong></h3><p><img src="https://ws3.sinaimg.cn/large/006tNbRwly1fy8usrkjfzj31ps08edic.jpg" style="zoom:35%"></p><ul><li><p>作用：在公共语义空间，对模态间的语义关系进行建模，将语义特征映射到哈希码。目标是学习这个映射函数。</p></li><li><p>输入：multi-label annotation</p></li><li><p>输出：$H^l=f^l (l;\theta^l)$，其中$f^{v,t, l}$是哈希函数，$\theta ^{v,t,l }$是要学的参数</p></li><li><p>网络结构</p><p>四层前馈神经网络，$L \rightarrow 4096\rightarrow 512 \rightarrow N ,N=K+c$</p></li><li><p>目标函数</p><script type="math/tex; mode=display">\begin{align}min_{B^l,\theta ^l,\hat L_l}=& \alpha J_1+\gamma J_2+\eta J_3 +\beta J4 \tag{1}\\=& -\alpha \sum^n_{i,j=1}(S_{i,j}\Delta^l_{i,j}-log(1+e^{\Delta^l_{i,j}}))\\=& -\gamma \sum^n_{i,j=1}(S_{i,j}\Gamma ^l_{i,j}-log(1+e^{\Gamma^l_{i,j}}))\\=& -\eta ||H^l-B^l||^2_F+\beta||\hat L^l-L||^2_F\\& s.t. B^l \in \{-1,1\}^K\end{align}</script><p> 其中$\alpha,\gamma,\beta,\eta$是要学习的参数，$\Delta^l<em>{i,j}=\frac {1}{2}(F^l</em>{<em>i})^T(F^l_{</em>j})，\Gamma ^l<em>{i,j}=\frac {1}{2}(H^l</em>{<em>i})^T(H^l_{</em>j}),F^{v,t,l} \in R^{s \times n}$表示公共语义空间里图像、文本、标签的语义特征，$S$是语义空间维度，是深度神经网络的输出层。</p></li><li><p>$B^{v,t,l}=sign(H^{v,t,l})\in {-1,1}^K$,三个网络学到了各自的哈希函数$H^{v,t,l}$，得到哈希码，通过$sign$函数得到二进制码，得到更加轻量级的特征。</p></li><li><p>$J_1$保证语义特征相似性，  $J_2$保证有相似label的instance要有相近的哈希码，  $J_3$是学习得到的哈希码二进制化的近似loss，  $J_4$是原label和预测的label的分类loss。</p></li></ul><h3 id="特征学习"><a href="#特征学习" class="headerlink" title="特征学习"></a><strong>特征学习</strong></h3><p>​    Loss函数和$(1)$中等式一样，但$F^l<em>{*i},F^l</em>{*j}$是用的LabNet生成的公共语义空间生成的，这可以确定相关性，从而避开模态鸿沟？这也是自监督学习起到的作用。</p><h4 id="TxtNet"><a href="#TxtNet" class="headerlink" title="TxtNet"></a><strong>TxtNet</strong></h4><p><img src="https://ws1.sinaimg.cn/large/006tNbRwly1fy8usvfukqj31du07476f.jpg" style="zoom:50%"></p><ul><li><p>目标：学习能将文本特征映射到哈希码的函数</p></li><li><p>生成网络：</p><ul><li><p>输入：词向量，BoW模型，但是这样的表示太稀疏，不适合生成哈希码，因此采用了多尺度混合模型来解决这个问题。</p></li><li><p>多尺度混合模型$\rightarrow 4096\rightarrow 512 \rightarrow N$</p></li><li><p>多尺度混合模型：5层平均池化（池化层大小：$1<em>1，2</em>2，3<em>3，5</em>5，10<em>10$）和$1</em>1$的卷积层，前者用来提取多尺度特征，后者用来融合提取到的多尺度特征。</p></li></ul></li><li><p>对抗网络结构：3层前馈网络（$F^{v,t,l} \rightarrow 4096 \rightarrow 4096 \rightarrow 1$）</p></li></ul><h4 id="ImgNet"><a href="#ImgNet" class="headerlink" title="ImgNet"></a><strong>ImgNet</strong></h4><p><img src="https://ws4.sinaimg.cn/large/006tNbRwly1fy8utcicvtj31e007076g.jpg" style="zoom:50%"></p><ul><li><p>目标：学习能将文本特征映射到哈希码的函数</p></li><li><p>生成网络有两种，一种是采用CNN-F的前7层提取图像特征+fc8+输出层（N个节点），第二种是CNN-F用vgg19代替，其他部分不变。</p></li></ul><h3 id="对抗学习"><a href="#对抗学习" class="headerlink" title="对抗学习"></a><strong>对抗学习</strong></h3><p><img src="https://ws4.sinaimg.cn/large/006tNbRwly1fy8utfi4s9j30ma0iw0v8.jpg" style="zoom:50%"></p><ul><li><p>输入：modality features和LabNet产生的语义特征</p></li><li><p>输出：0/1（判断标签来自ImgNet或TxtNet时输出0，来自LabNet输出为1）</p></li><li><p>在公共空间分配给语义特征的模态标签表示为$Y=    {y<em>i}^{3\times n}</em>{i=1},y_i\in{0,1}$</p><ul><li>模态标签：$Y^l={y<em>i^l}^{n}</em>{i=1},y_i^l=1$</li><li>图像和文本的模态标签：$Y^{v,t}={y<em>i^{v,t}}^{n}</em>{i=1},y_i^{v,t}=0$</li></ul></li><li><p>目标函数：$min<em>{\theta ^{*,l}</em>{adv}}L^{<em>,l}<em>{adv}=\sum ^{2\times n}</em>{i=1}||D^{</em>,l}(x^{<em>,l}_{i})-y^{</em>,l}<em>{i}||^2_2,<em>=v,t$，$x^{</em>,l}</em>{i}$是公共空间的语义特征，$y^{*,l}_{i}$是判别值，相当于一个二元分类器</p></li></ul><h3 id="训练过程的伪代码"><a href="#训练过程的伪代码" class="headerlink" title="训练过程的伪代码"></a><strong>训练过程的伪代码</strong></h3><p><img src="https://ws1.sinaimg.cn/large/006tNbRwly1fy8utjtnfyj30zk0n6wii.jpg" style="zoom:50%"></p><h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p><img src="https://ws4.sinaimg.cn/large/006tNbRwly1fy8utn23duj30lo050gmn.jpg" style="zoom:50%"></p><h3 id="评估"><a href="#评估" class="headerlink" title="评估"></a>评估</h3><p>MAP、PR、Precision@top k</p><h3 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h3><p>5个基于浅层结构方法（CVH , STMH , CMSSH , SCM ,SePH ），一个基于深层结构的方法（DCMH）</p><h3 id="超参数的确定"><a href="#超参数的确定" class="headerlink" title="超参数的确定"></a>超参数的确定</h3><p>从数据库随机选择2000个数据点作为验证集，最终设置$\alpha=\gamma=1,\beta=\eta=10^{-4}$</p><p><img src="https://ws4.sinaimg.cn/large/006tNbRwly1fy8utqt4loj317207kmyt.jpg" style="zoom:50%"></p><h3 id="Hamming-Ranking"><a href="#Hamming-Ranking" class="headerlink" title="Hamming Ranking"></a>Hamming Ranking</h3><p>SSAH分别采用CNN-F做实验，与6个baseline进行对比，SSAH的效果都更好：</p><ul><li><p>与5个基于浅层结构方法的baseline相比，在MIRFLICKR-25K数据集上，SSAH的MAP值能高10%；</p></li><li><p>与1个基于深度结构方法的baseline相比，在MIRFLICKR-25K数据集上，SSAH的MAP值能高5%。</p></li></ul><p><img src="https://ws1.sinaimg.cn/large/006tNbRwly1fy8uttl8bhj314e0hktdt.jpg" style="zoom:50%"></p><p>SSAH分别采用VGG19做实验，与6个baseline进行对比，SSAH的效果都更好，且几乎所有的效果比用CNN-F更好；与5个基于浅层结构方法的baseline相比，在MIRFLICKR-25K数据集上，SSAH的MAP值能高5%；</p><p><img src="https://ws1.sinaimg.cn/large/006tNbRwly1fy8utwg4nmj31480hkgqn.jpg" style="zoom:50%"></p><h3 id="Hash-Lookup"><a href="#Hash-Lookup" class="headerlink" title="Hash Lookup"></a>Hash Lookup</h3><p>SSAH使用CNN-F作为ImgNet的生成网络；</p><p>Hamming距离小于某个值认为是正样本，这个值称为Hamming Radius，改变Radius可以改变Precision-Recall的值，于是可以得到P-R曲线，P-R曲线与坐标轴围成的面积越大，说明效果越好。</p><p>PR curve结果图中，SSAH比其他几个baseline的效果都好。</p><p><img src="https://ws1.sinaimg.cn/large/006tNbRwly1fy8utz553zj31760q6wxg.jpg" style="zoom:50%"></p><h3 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h3><p>SSAH-1：不使用自监督学习；SSAH-2：TxtNet替换为全连接网络；SSAH-3：去掉对抗学习</p><p><img src="https://ws3.sinaimg.cn/large/006tNbRwly1fy8uu2e5zej30ky09qabs.jpg" style="zoom:50%"></p><p>数据集是 MIRFLICKR-25K，哈希码长度为16bits;</p><p>可以看出SSAH-1的曲线的值都是最低，即自监督语义网络能够显著提升检索性能；</p><p>同样SSAH-2，SSAH-3曲线的值都低于SSAH，足以证明TxtNet和对抗学习在这其中起到的作用。</p><h3 id="Training-Efficiency"><a href="#Training-Efficiency" class="headerlink" title="Training Efficiency"></a>Training Efficiency</h3><p><img src="https://ws2.sinaimg.cn/large/006tNbRwly1fy8uu74rr5j30ks08c3zo.jpg" style="zoom:50%"></p><p>​    SSAH比基于深度结构方法的DCMH能更快收敛，且MAP值也更高，说明SSAH能从高纬语义特征和哈希码中学到更多监督信息，训练的ImgNet,TxtNet对于找到模态间的关系更有效。</p><h3 id="和ACMR对比"><a href="#和ACMR对比" class="headerlink" title="和ACMR对比"></a>和ACMR对比</h3><ul><li><p>ACMR是目前跨模态检索效果最好的方法，也第一个使用对抗学习，但它不是基于哈希的方法；</p></li><li><p>在NUS-WIDE-10k 数据集的10个最大的类里，随机选取10,000 image/text pairs；</p></li></ul><p><img src="https://ws1.sinaimg.cn/large/006tNbRwly1fy8uuaoafcj30hi048mxi.jpg" style="zoom:50%"></p><p>原因分析：可能是因为SSAH采用了两个对抗网络，能学好模态间的特征分布，捕捉模态关系。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>​    为了提升跨模态检索的效率，该论文提出的SSAH，融合了多标签的自监督语义网络和对抗学习，使得不同模态间语义相关性最大化和特征分布一致性。</p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>TF1-MNIST</title>
      <link href="/2018/04/01/TF1-MNIST/"/>
      <url>/2018/04/01/TF1-MNIST/</url>
      
        <content type="html"><![CDATA[<p>MNIST是一个计算机视觉数据集，包含各种手写数字图片，也包含每一张图片的标签（即，该数字是几）。<br><a id="more"></a><br>像这组图，对应标签是5,0,4,1.<br><img src="/images/TF1/TF1_1.png" alt=""></p><h3 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h3><p>通过训练一个模型用于预测图片里的数字，从而了解tensorflow的工作流程和ML的概念。</p><h3 id="使用模型"><a href="#使用模型" class="headerlink" title="使用模型"></a>使用模型</h3><p>softmax regression</p><h3 id="MNIST数据集"><a href="#MNIST数据集" class="headerlink" title="MNIST数据集"></a>MNIST数据集</h3><ul><li>mnist.train:60000行训练数据集</li><li>mnist.test:10000行测试数据集（用于评估模型性能，易泛化到其他数据集）</li><li>mnist.train.images：训练用的图片，设为xs<br>每张图片有28<em>28个像素点，用长度为28</em>28=784的向量表示，如下图（实际上，这样的表示会丢失图片的二维结构信息，但这里的softmax回归不会用到结构信息）<br><img src="/images/TF1/TF1_2.png" alt=""><br>xs是一个形状为[60000,784]（图片索引，像素点索引）的张量，存的值表示图片中像素的强度，取值介于0和1之间</li></ul><p><img src="/images/TF1/TF1_3.png" alt=""></p><ul><li>mnist.train.labels:训练用标签，设为ys。标签是介于0到9的数字。<br>表示为one-hot vectors（one-hot向量除了某一维数字是1，其余都是0）.数字n将表示为第n维为1，其余维度为0的10维向量。labels是一个[60000,10]的数字矩阵.</li></ul><h3 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h3><p>softmax回归模型：该模型分两步，可以给不同的对象分配概率。</p><h4 id="step-1"><a href="#step-1" class="headerlink" title="step 1"></a>step 1</h4><p> 对图片像素值进行加权求和，以求得该图片属于某个数字类的证据（evidence）。如果证据充分，则权值为正数，反之为负数。</p><p>So，对于给定的输入图片x，代表的是数字i的证据可以表示为：<br>\begin{equation}<br>evidence<em>i=\sum_j W</em>{i,j}x_j+b_i<br>\end{equation}<br>$W_i$是权重，$b_i$是数字$i$类的偏置量，$j$是给定图片$x$的像素索引用于像素求和。</p><h4 id="step-2"><a href="#step-2" class="headerlink" title="step 2"></a>step 2</h4><p>再用softmax函数把证据转换为概率y：<br>\begin{equation}<br>y=softmax(evidence)<br>\end{equation}<br>softmax函数可以将图片对应每个数字的匹配度转换为概率值<br>\begin{equation}<br>softmax（x）= normalize(exp(x))<br>\end{equation}</p><p>\begin{equation}<br>softmax(x)_i=\frac{exp(x_i)}{\sum_j exp(x_j)}<br>\end{equation}</p><h4 id="模型过程表示图"><a href="#模型过程表示图" class="headerlink" title="模型过程表示图"></a>模型过程表示图</h4><p><img src="/images/TF1/TF1_4.png" alt=""><br>用等式表示为：<br><img src="/images/TF1/TF1_5.png" alt=""><br>进一步表示为：<br>\begin{equation}<br>y=softmax(Wx+b)<br>\end{equation}</p><h3 id="实现回归模型"><a href="#实现回归模型" class="headerlink" title="实现回归模型"></a>实现回归模型</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">import input_data</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(&quot;MNIST_data/&quot;, one_hot=True)</span><br><span class="line"></span><br><span class="line"># 通过操作符合标量来描述可交互的操作单元</span><br><span class="line"># x是一个占位符，当运行计算时，才输入</span><br><span class="line"># 输入任意数量的mnist图像，每一张图展开为784维向量，用2维浮点数张量来表示，shape是[None,784]</span><br><span class="line">x=tf.placeholder(tf.float32,[None,784]) </span><br><span class="line"></span><br><span class="line">W=tf.Variable(tf.zeros([784,10]))#Variable表示可修改的张量</span><br><span class="line">b=tf.Variable(tf.zeros([10]))</span><br><span class="line"></span><br><span class="line">#定义模型</span><br><span class="line">y=tf.nn.softmax(tf.matmul(x,W)+b) </span><br><span class="line"></span><br><span class="line">#y_用于输入正确值</span><br><span class="line">y_=tf.placeholder(&quot;float&quot;,[None,10])</span><br><span class="line"></span><br><span class="line"># 用于评估模型好坏的cost函数 cross_entropy，</span><br><span class="line"># 是100张图片的交叉熵总和</span><br><span class="line"># 100个数据点的预测表现比单一数据点的表现能更好描述模型性能</span><br><span class="line">cross_entropy=-tf.reduce_sum(y_*tf.log(y)) </span><br><span class="line"></span><br><span class="line">#用梯度下降法以0.01的学习速率最小化交叉熵</span><br><span class="line">#给描述的计算的那张图里面增加一系列新的计算操作单元用于实现反向传播算法和梯度下降算法</span><br><span class="line">train_step=tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line">#初始化创建的变量</span><br><span class="line">init=tf.initialize_all_variables()</span><br><span class="line"></span><br><span class="line">#在一个Session里面启动模型，并初始化变量</span><br><span class="line">sess=tf.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line">#开始训练模型，让模型循环训练1000次</span><br><span class="line">#该循环的每个步骤中，随机抓取训练数据中的100个批处理数据点</span><br><span class="line"># 然后用这些数据点作为参数替换之前的占位符来运行train_step</span><br><span class="line">#使用一小部分的随机数据来进行训练被称为随机训练（stochastic training）</span><br><span class="line">#这里更确切的说是随机梯度下降训练</span><br><span class="line">for i in range(1000):</span><br><span class="line">    batch_xs,batch_ys=mnist.train.next_batch(100)</span><br><span class="line">    sess.run(train_step,feed_dict=&#123;x:batch_xs,y_:batch_ys&#125;)</span><br><span class="line"></span><br><span class="line">#评估模型性能</span><br><span class="line">#用 tf.equal 来检测预测是否真实标签匹配(索引位置一样表示匹配)</span><br><span class="line">#correct_prediction 是一组布尔值</span><br><span class="line">correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_,1))#argmax 会返回最大值所在的索引</span><br><span class="line"></span><br><span class="line">#把布尔值转换成浮点数，然后取平均值</span><br><span class="line">accuracy=tf.reduce_mean(tf.cast(correct_prediction,&quot;float&quot;))</span><br><span class="line"></span><br><span class="line">#计算所学习到的模型在测试数据集上面的正确率</span><br><span class="line">print(sess.run(accuracy,feed_dict=&#123;x:mnist.test.images,y_:mnist.test.labels&#125;))</span><br><span class="line"></span><br><span class="line">#最终结果值应该大约是91%</span><br></pre></td></tr></table></figure><h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p>tensorflow官方文档中文版</p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>ML1-Perceptron</title>
      <link href="/2018/04/01/ML1-Perceptron/"/>
      <url>/2018/04/01/ML1-Perceptron/</url>
      
        <content type="html"><![CDATA[<h1 id="感知机"><a href="#感知机" class="headerlink" title="感知机"></a>感知机</h1><h3 id="什么是感知机"><a href="#什么是感知机" class="headerlink" title="什么是感知机"></a>什么是感知机</h3><p>基于误分类的损失函数，利用梯度下降法对损失函数进行极小化，求得感知机模型。<br><a id="more"></a><br>分为原始形式和对偶形式。<br>感知机是1957年由Rosenblatt提出，是神经网络和SVM的基础。</p><h3 id="1-感知机模型"><a href="#1-感知机模型" class="headerlink" title="1. 感知机模型"></a>1. 感知机模型</h3><p>定义（是什么我已经忘记了）<br>假设输入空间（特征空间）是$ X \subseteq R^n  $,输出空间是$Y = { -1,+1 } $，输入$y\in Y$表示实例的类别。由输入空间到输出空间的如下函数<br>                               \begin{equation}f(x)=sign (w\cdot x + b)\end{equation}<br>称为感知机。其中，w和b为感知机模型参数，$w \in R^n$叫做权值或权值向量，$b \in R$叫做偏置（bias），$w \cdot x$表示w和x的內积。sign是符号函数，即<br>\begin{equation}<br>f(x)=<br>\begin{cases}<br>+1&amp; \text{$x \geq 0$}\<br>-1&amp; \text{x &lt; 0}<br>\end{cases}<br>\end{equation}<br>感知机是一种线性分类模型，属于判别模型。感知机模型的假设空间是定义在特征空间中的所有线性分类模型（linear classification model）或线性分类器（linear classifier），即函数集合${f|f(x)=w\cdot x+b}$.<br>    感知机的几何解释：线性方程<br>    \begin{equation}<br>    w\cdot x+b=0<br>\end{equation}<br>对应于特征空间$R^n$中的一个超平面S，w是S的法向量，b对应于该超平面的截距。S将该特征空间分为两部分，位于两部分的点分别被分为正、负两类。称超平面S为分离超平面（separating hyperplane）.<br>    感知机学习，由训练数据集（实例的特征向量和类别）<br>    \begin{equation}<br>    T={(x_1,y_1),(x_2,y_2),…(x_N,y_N)}<br>    \end{equation}<br>其中，$x_i \in X=R^n,y_i \in Y={+1,-1},i=1,2,…N$,求得感知机模型，即求模型参数w，b。</p><h3 id="2-学习策略"><a href="#2-学习策略" class="headerlink" title="2. 学习策略"></a>2. 学习策略</h3><p>定义：数据集的线性可分性，给定一个数据集，同上，如果存在某个超平面S<br>\begin{equation}<br>w\cdot x+b=0<br>\end{equation}<br>能够将数据集的正实例点和负实例点完全正确的划分到超平面的两侧，即对所有$y_i=+1的实例i，有w\cdot w_i+b&gt;0$,对所有$y_i=-1的实例i，有w\cdot w_i+b&lt;0$，则该数据集T为线性可分数据集（linearly separable data set）；否则，称数据集T线性不可分。</p><h5 id="感知机学习策略"><a href="#感知机学习策略" class="headerlink" title="感知机学习策略"></a>感知机学习策略</h5><p>假设数据集是线性可分的，感知机学习的目标是能将该数据集完全正确分离的超平面，即需要去顶参数w，b，需要确定学习策略，即定义损失函数并最小化。<br>损失函数可以是误分类点的总数，但这样不是w,b的连续可导函数，难优化。<br>感知机采用的是误分类点到超平面S的总距离。<br>输入空间$R^n$中任一点$x<em>o$到超平面S的距离：<br>\begin{equation}<br>\frac{1}{||w||} |w\cdot x_0+b|<br>\end{equation}<br>这里，$||w||$是$w的L2$范数（欧式距离是一种$L2$范数）。<br>    对于，误分类的数据$(x_i,y_i)$来说，<br>\begin{equation}<br>    -y_i(w\cdot x_i +b)&gt;0<br>\end{equation}<br>成立。因此误分类点$x_i$到超平面S的距离是<br>\begin{equation}<br>-\frac{1}{||w||} （w\cdot x_i+b）<br>\end{equation}<br>对于误分类集合M，所有误分类点到超平面S的总距离为<br>\begin{equation*}<br>-\frac{1}{||w||}\sum</em>{x<em>i\in M } y_i(w\cdot x_i+b)<br>\end{equation*}<br>不考虑范数，可以得到感知机$sign(w\cdot x+b)$学习的损失函数（是感知机的经验风险函数）:<br>\begin{equation}<br>L(w,b)=-\sum</em>{x_i\in M } y_i(w\cdot x_i+b)<br>\end{equation}<br>一个特定的样本点的损失函数：在误分类时是参数w,b的线性函数，在正确分类是，损失函数的值为0。因此，给定训练数据集T，损失函数$L(w,b)是w,b$的连续可导函数。<br>感知机学习的策略，即在假设空间中选取使损失函数最小的模型参数$w,b$，即感知机模型。</p><h4 id="3-学习算法"><a href="#3-学习算法" class="headerlink" title="3. 学习算法"></a>3. 学习算法</h4><p>感知机学习问题转化为求解损失函数式的最优化问题，最优化的方法是随机梯度下降法。</p><h5 id="3-1-原始形式"><a href="#3-1-原始形式" class="headerlink" title="3.1 原始形式"></a>3.1 原始形式</h5><p>给定一个数据集（同前面的描述），求参数$w,b$，使其为以下损失函数极小化问题的解<br>\begin{equation}<br>\min<em>{w,b}L(w,b)=-\sum</em>{x<em>i\in M } y_i(w\cdot x_i+b)<br>\end{equation}<br>学习算法具体采用随机梯度下降（stochastic gradient descent）。首先，任意选取一个超平面$w_0,b_0$，然后用随机选取一个误分类点使其梯度下降。<br>\begin{equation}<br>\nabla_wL(w,b)=-\sum</em>{x<em>i\in M}y_ix_i<br>\end{equation}<br>\begin{equation}<br>\nabla_bL(w,b)=-\sum</em>{x_i\in M}y_i<br>\end{equation}<br>假设M固定，损失函数$L(w,b)$的梯度有由上述两式给出。<br>随机选取一个误分类点$(x_i,y_i)$，对$w,b$进行更新：<br>\begin{equation}<br>w\gets w+\eta y_ix_i<br>\end{equation}<br>\begin{equation}<br>b\gets w+\eta y_i<br>\end{equation}<br>$\eta（0\le \eta \le 1）$是步长，即学习率（learning rate）。通过迭代不断减小损失函数，直到为0.<br>算法如下：<br>输入：训练数据集T，学习率<br>输出：$w,b$；感知机模型$f(x)=sign (w\cdot x + b)$<br>（1）选取初值$w_0,b_0$<br>（2）在训练集中选取数据$(x_i,y_i)$<br>（3）如果$y_i(w\cdot x_i+b)\le 0$<br>\begin{equation}<br>w\gets w+\eta y_ix_i<br>\end{equation}<br>\begin{equation}<br>b\gets w+\eta y_i<br>\end{equation}<br>（4）转至步骤2，直至训练集中么有误分类点。<br>感知机学习算法由于采用不同的初值或选取不同的误分类点，解可以不同。</p><h5 id="3-2-算法收敛性证明"><a href="#3-2-算法收敛性证明" class="headerlink" title="3.2 算法收敛性证明"></a>3.2 算法收敛性证明</h5><p>对于线性可分数据集感知机学习算法原始形式收敛，即经过有限次的迭代，可以得到一个能将训练集完全正确划分的超平面和感知机模型。<br>感知机算法在训练数据集上的误分类次数k满足不等式：<br>\begin{equation}<br>k\le\lgroup \frac{R}{\gamma}\rgroup^2<br>\end{equation}</p><h5 id="3-3-对偶形式"><a href="#3-3-对偶形式" class="headerlink" title="3.3 对偶形式"></a>3.3 对偶形式</h5><p>将$w,b$表示为实例$x<em>i和标记y_i$的线性组合形式，通过求解洗漱从而求得$w和b$。假设初始值$w_0,b_0$均为0。对误分类点$(x_i,y_i)$通过<br>\begin{equation}<br>w\gets w+\eta y_ix_i<br>\end{equation}<br>\begin{equation}<br>b\gets w+\eta y_i<br>\end{equation}<br>不断修改$w,b$，设修改n次，则$w,b$关于$(x_i,y_i)$的增量分别为$\alpha_iy_ix_i和\alpha_iy_i，\alpha_i=n_i\eta$，最后学习都的$w,b$可以分别表示为<br>\begin{equation}<br>w=\sum</em>{i=1}^N\alpha<em>iy_ix_i<br>\end{equation}<br>\begin{equation}<br>b\sum</em>{i=1}^N\alpha_iy_i<br>\end{equation}<br>这里，$\alpha_i\ge0,i=1,2,…N,当\eta=1时，表示第i$个实例点由于误分而进行更新的次数。更新次数越多，距离分离超平面越近，就越难正确分类。这样的实例对学习结果影响最大。</p><h5 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h5><p>输入：线性可分数据集T，学习率<br>输出：$\alpha,b$，感知机模型$f(x)=sign\lgroup \sum<em>{j=1}^N\alpha_iy_ix_i +b \rgroup，其中\alpha=(\alpha_1,\alpha_2,…\alpha_N)^T$<br>（1）$\alpha \gets 0,b\gets 0$<br>（2）在训练集中选取数据$(x_i,y_i)$<br>（3）如果$y_i\lgroup \sum</em>{j=1}^N\alpha_iy_ix_i +b \rgroup\le0$<br>\begin{equation}<br>\alpha_i\gets\alpha_i+\eta<br>\end{equation}<br>\begin{equation}<br>b\gets b+\eta<br>\end{equation}<br>（4）转至（2）直至没有误分类数据<br>对偶实例中训练实例仅以內积的形式出现，可以预先将训练集中实例间的內积计算出来并以矩阵形式存储，即Gram 矩阵。<br>同样，对偶形式也是收敛的，存在多个解。</p><h3 id="4-习题"><a href="#4-习题" class="headerlink" title="4. 习题"></a>4. 习题</h3><p>（1）验证感知机为什么不能表示异或<br>虽然通过画图或者异或表，可以看出，但还想到怎样形式化的证明。待续<br>（2）构建从训练数据集求解感知机模型的例子<br>（3）证明一下定理：样本集线性可分的充分必要条件是正实例点集所构成的凸壳，与负实例点集所构成的凹壳互不相交。</p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>Hello World</title>
      <link href="/2018/04/01/hello-world/"/>
      <url>/2018/04/01/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.<br><a id="more"></a></p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>ML2-knn notes</title>
      <link href="/2018/04/01/ML2-knn-notes/"/>
      <url>/2018/04/01/ML2-knn-notes/</url>
      
        <content type="html"><![CDATA[<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>&emsp;&emsp;k近邻法（k-nearest neighbor,k-NN）是一种基本分类与回归方法。<br>&emsp;&emsp;给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的k个实例，这k个实例的多数属于某个类，就把该输入实例分为这个类。<br><a id="more"></a></p><h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><p> 输入：训练数据集</p><script type="math/tex; mode=display">T=\{(x_1,y_1),(x_2,y_2),..,(x_N,y_N)\}</script><p> 其中，$x<em>i \in X \subseteq R^n$为实例的特征向量，$y_i \in Y={c_1,c_2,…,c_k}$为实例的类别，$i=1,2,…,N$；实例特征向量x;<br> 输出：实例$x$所属的类$y$<br> （1）根据给定的距离度量，在训练集T中寻找出距离x最近的k个点，涵盖这k的点的领域记作$N_k(x)$；<br> （2）在$N_k(x)$中根据分类决策规则（eg:多数表决），确定x所属的类别y：<br>  \begin{equation}<br>y=arg \max</em>{c<em>j} \sum</em>{x_i \in N_k(x)} I(y_i=c_i), i=1,2,…,K<br> \end{equation}<br> 其中，$I$为指示函数，即当$y_i=c_i时I为1，否则I为0$。<br> 特殊情况是$k=1$的情形，称为最近邻算法。</p><h4 id="k近邻模型"><a href="#k近邻模型" class="headerlink" title="k近邻模型"></a>k近邻模型</h4><p> &emsp;&emsp;k近邻法的模型对应于特征空间的划分。模型由三个基本要素—距离度量、k值的选择和分类决策规则决定。</p><h4 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h4><p>&emsp;&emsp;当上述三个要素确定后，对于任何一个新的输入实例，所属的类唯一地确定。<br>&emsp;&emsp;特征空间中，对每个训练实例点$x_i$，距离该点比其他店更近的所有点组成的一个区域，叫做单元（cell）。每个训练实例点拥有一个单元，所有训练实例点的单元构成对特征空间的一个划分。最近邻法将实例$x_i$的类$y_i$作为其单元中所有点的类标记（class label）。则每个单元的实例点的类别是确定的。</p><h4 id="距离度量"><a href="#距离度量" class="headerlink" title="距离度量"></a>距离度量</h4><p>&emsp;&emsp;特征空间中两个实例点的距离是这两个实例点相似度的反映。k近邻模型的特征空间一般是n维实数向量空间$R^n$。使用的距离是欧式距离，也可以是其他距离，比如更一般的$L<em>P$距离（$L_P$ distance）或Minkowski距离。<br>&emsp;&emsp;设特征空间X是n维实数向量空间$R^n$，$x_i,x_j \in X,<br>x_i=(x_i^{(1)},x_i^{(2)},…,x_i^{(n)})^T$，<br>$x_j=(x_j^{(1)},x_j^{(2)},…,x_j^{(n)})^T$，$x_i,x_j的L_P距离定义为：$<br>  \begin{equation}<br>L_P(x_i,x_j)=\lgroup \sum</em>{l=1}^n |x<em>i^{(l)}-x_j^{(l)}|^p\rgroup ^{\frac{1}{p}}<br> \end{equation}<br> 当$p \ge 1。当p=2$时，称为Euclidean distance，即<br>  \begin{equation}<br>L_2(x_i,x_j)=\lgroup \sum</em>{l=1}^n |x<em>i^{(l)}-x_j^{(l)}|^2\rgroup ^{\frac{1}{2}}<br> \end{equation}<br> 当$p =1$时，称为Manhattan distance，即<br>  \begin{equation}<br>L_1(x_i,x_j)= \sum</em>{l=1}^n |x<em>i^{(l)}-x_j^{(l)}|<br> \end{equation}<br> 当$p=\infty$时，是各个坐标距离的最大值，即<br>   \begin{equation}<br>L</em>\infty(x<em>i,x_j)= \max</em>{l}|x_i^{(l)}-x_j^{(l)}|<br> \end{equation} </p><h4 id="k值的选择"><a href="#k值的选择" class="headerlink" title="k值的选择"></a>k值的选择</h4><p>&emsp;&emsp;k值的选择会对k近邻法的结果产生重大影响。<br>&emsp;&emsp;如果选择较小的k值，相当于用较小的邻域中的训练实例进行预测，学习的近似误差（approximation error）会减小，只有与输入实例较近的（相似的）训练实例才会对预测结果起作用。但缺点是学习的估计误差（estimation error）会增大，预测结果会对近邻的实例点非常敏感。k值的减小意味着整体模型变得负责，容易发生过拟合。<br>&emsp;&emsp;如果k值较大，相当于用较大邻域里的训练实例进行预测。优点是可以减少学习的估计误差，但缺点就是会增大近似误差。这是与输入实例较远的（不太相似）的训练实例也会对预测起作用，是预测发生错误。k值的增大意味着模型变得更简单。<br>&emsp;&emsp;如果k=N，则将输入实例预测为训练实例中最多的类。即模型过于简单，完全忽略了训练实例中的大量有用信息，不可取。<br>&emsp;&emsp;实际应用中，k值一般去一个比较小的数值。通常常采用交叉验证法（将原始数据(dataset)进行分组,一部分做为训练集(train set),另一部分做为验证集(validation set or test set),首先用训练集对分类器进行训练,再利用验证集来测试训练得到的模型(model),以此来做为评价分类器的性能指标）来选取最优值。</p><h4 id="分类决策规则"><a href="#分类决策规则" class="headerlink" title="分类决策规则"></a>分类决策规则</h4><p>&emsp;&emsp;多用是<strong>多数表决</strong>，即由输入实例的k个近邻的训练实例中的多数类决定输入实例的类。多数表决的规则等价于经验风险最小化。</p><h4 id="k近邻法的实现：kd树"><a href="#k近邻法的实现：kd树" class="headerlink" title="k近邻法的实现：kd树"></a>k近邻法的实现：kd树</h4><p>&emsp;&emsp;实现的过程中，主要的问题是如何对训练数据进行快速k近邻搜索。这在特征空间的维数大，及训练数据容量大时尤其必要。<br>&emsp;&emsp;最简单的方法是线性扫描（linear scan）。需要计算输入实例与每一个训练实例的距离。当训练集很大时，计算非常耗时，不可取。<br>&emsp;&emsp;为了改善，可以使用特殊的结构存储训练数据，比如kd树（kd tree）。</p><h5 id="构造kd树"><a href="#构造kd树" class="headerlink" title="构造kd树"></a>构造kd树</h5><p><strong>例：</strong>给定一个二维空间的数据集：<br>\begin{equation}<br>T={(2,3)^T,(5,4)^T,(9,6)^T,(4,7)^T,(8,1)^T,(7,2)^T}<br>\end{equation}<br>构造一个平衡kd树。<br><strong>解：</strong></p><ul><li>根节点对应包含数据集T的矩形，选择$x^{(1)}$轴，6个数据点的$x^{(1)}$坐标中位数是7，以平面$x^{(1)}=7$将空分为左右两个子矩形（子节点）；</li><li>左矩形以$x^{(2)}=4$分为两个子矩形，右矩形以$x^{(2)}=6$分为两个子矩形；<br>如此递归，最后得到如下图所示的特征空间划分和kd树。</li></ul><p><img src="/images/features_zone_classfy.png" alt=""><br><img src="/images/kd_tree.png" alt=""></p><h5 id="搜索kd树"><a href="#搜索kd树" class="headerlink" title="搜索kd树"></a>搜索kd树</h5><p>输入：已构造的kd树，目标点x；<br>输出：x的最近邻</p><ul><li>（1）在kd树中找到包含目标的x的叶节点：从根节点出发，递归地向下访问kd树。若目标点x当前维的坐标小于切分点的坐标，则移动到左子节点，否则移动到右子节点。直到子节点为叶节点为止。</li><li>（2）以此叶节点为“当前最近点”</li><li>（3）递归地向上回退，在每个节点进行下列操作：</li><li>（a）如果该节点保存的实例点比当前最近点距离目标更近，则以该实例点为“当前最近点”；</li><li>（b）当前最近点一定存在于该节点一个子节点对应的区域。检查该子节点的父节点的另一个子节点对应的区域是否有更近的点。具体来说，是检查另一子节点对应的区域是否以目标点为球心，以目标点与“当前最近点”间的距离为半径的球体相交。<br>  &emsp;如果相交，可能在另一个子节点对应的区域内存在距目标点更近的点，移动到另一个子节点。接着，递归的进行最近邻搜索；<br>   &emsp;如果不相交，向上回退。</li><li>（4）当回退到根节点是，搜索结束。最后的“当前最近点”即x的最近邻点。</li></ul><p>&emsp;&emsp;kd树更适用于训练实例远大于空间维数时的k近邻搜索。当空间维数接近训练实例数时，效率会迅速下降，几乎接近线性扫描。</p><h3 id="python实现"><a href="#python实现" class="headerlink" title="python实现"></a>python实现</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import operator</span><br><span class="line"></span><br><span class="line">def Dataset():</span><br><span class="line">    np.random.seed(13)</span><br><span class="line">    dataList=np.random.randint(1,10,8)</span><br><span class="line">    print(&apos;dataList&apos;,dataList)</span><br><span class="line">    data=np.array(dataList).reshape(4,2)</span><br><span class="line">    print(&apos;data&apos;,data)</span><br><span class="line">    lables=[&apos;A&apos;,&apos;B&apos;,&apos;A&apos;,&apos;B&apos;]</span><br><span class="line">    return data,lables</span><br><span class="line">def classfy(target,dataset,labels,k):</span><br><span class="line">    dataSize=dataset.shape[0]</span><br><span class="line"></span><br><span class="line">    #compute Euclidean distance=sqrt(sum of all the difference between tartget and dataSet)</span><br><span class="line">    minus=np.tile(target,(dataSize,1))-dataset</span><br><span class="line">    temp=minus**2</span><br><span class="line">    temp1=temp.sum(axis=1) # sum of each row</span><br><span class="line">    distance=temp1**0.5</span><br><span class="line"></span><br><span class="line">    sortedDistIdx=distance.argsort()# return the indcies of sorted ele,emts</span><br><span class="line">    count=&#123;&#125;</span><br><span class="line">    #count labels</span><br><span class="line">    for i in range(k):</span><br><span class="line">        theLabel=labels[sortedDistIdx[i]]</span><br><span class="line">        print(&apos;label=&#123;&#125;,i=&#123;&#125;&apos;.format(theLabel,i))</span><br><span class="line">        count[theLabel]=count.get(theLabel,0)+1</span><br><span class="line"></span><br><span class="line">    sortedCount=sorted(count.items(),key=operator.itemgetter(1),reverse=True)</span><br><span class="line">    return sortedCount[0][0]</span><br><span class="line"></span><br><span class="line">data,label=Dataset()</span><br><span class="line">target=[3,2]</span><br><span class="line"></span><br><span class="line">className=classfy(target,data,label,3)</span><br><span class="line">print(&apos;target is class:&apos;,className)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> ML notes </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>kannsou</title>
      <link href="/2018/03/22/kannsou/"/>
      <url>/2018/03/22/kannsou/</url>
      
        <content type="html"><![CDATA[<p>今年の報告さすかに遅いですね。<br>でも、たとえそれでも、なんか何も書けない。<br>多分頭が退化したかな。<br>先ほど「誰も知らない」を読んった。二つ感動されったことがある。<br><a id="more"></a><br>一つは気候の交代を管掌する神様が人としての言葉が見られった、予定の移動が延期した。神様は言葉に帰させない。でも、彼女は新しい言能者の証拠を見た後に、「あの人」を思えました、何十年前に亡くなったの「あの人」。先代の言能者。神様たちは「あの人」の物見た後とても喜びてす。きっと「あの人」とたくさんいい思い出があるでしょう。そして、神様たちは移動し続けました。<br>なぜ僕を感動されましたか自分もよく分からない。<br>もう一つは、斌のかぞくが全部亡くなった後、おばあちゃんから伝えたいのは蛇は呪いではなく、お守りだ。彼はその後一人で生き続けならなっきゃ。確かにとても、とても気の毒のことです。でも、皆は彼をお守り続けています。<br>「あの家にはもう新しいご先祖様がお守ってあげますから。」<br>すごく悲しですけど、でも前を歩く勇気をご先祖様からもらえました。</p><p>はるき　2018年２月２６日　朝３時半</p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>blogtest</title>
      <link href="/2018/03/22/blogtest/"/>
      <url>/2018/03/22/blogtest/</url>
      
        <content type="html"><![CDATA[<p>不得不说，对于一个半吊子的程序员，安装并成功部署hexo是在是太难了。<br><a id="more"></a><br>前前后后可能有3,4次尝试了。<br>之前有一次达到过这一步，但由于当时时间不太充足，嫌弃主题太丑，就又回csdn博客了。<br>之后不晓得咋回事，这个hexo博客总是配置不行。<br>然后顺便把我pycharm也搞垮。<br>好在pycharm和GitHub重归于好了。<br>也不知道这一次能不能成功。</p>]]></content>
      
      
      
    </entry>
    
  
  
</search>
